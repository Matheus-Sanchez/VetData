"""
Classe base abstrata para todos os scrapers de sites
Define interface comum e funcionalidades compartilhadas
"""

import time
import random
import logging
from abc import ABC, abstractmethod
from typing import List, Dict
from dataclasses import asdict
from datetime import datetime

from estruturas_dados import InfoProduto
from gerenciador_dados import GerenciadorDados
from gerenciador_conexoes import GerenciadorConexaoHibrida

logger = logging.getLogger(__name__)

class ScraperBase(ABC):
    """
    Classe abstrata que define interface comum para todos os scrapers
    Implementa funcionalidades b√°sicas compartilhadas entre sites
    """
    
    def __init__(self, 
                 gerenciador_conexao: GerenciadorConexaoHibrida, 
                 gerenciador_dados: GerenciadorDados,
                 modo_teste: bool = False):
        """
        Inicializa scraper base
        
        Args:
            gerenciador_conexao: Gerenciador h√≠brido de conex√µes
            gerenciador_dados: Gerenciador de dados dos medicamentos
            modo_teste: Se True, coleta apenas 1 produto por medicamento
        """
        self.gerenciador_conexao = gerenciador_conexao
        self.gerenciador_dados = gerenciador_dados
        self.modo_teste = modo_teste
        
        # Estat√≠sticas do scraper
        self.estatisticas = {
            'medicamentos_processados': 0,
            'produtos_encontrados': 0,
            'medicamentos_sem_resultado': 0,
            'tempo_inicio': None,
            'tempo_fim': None
        }
    
    @property
    @abstractmethod
    def nome_site(self) -> str:
        """Nome do site para identifica√ß√£o"""
        pass
    
    @property
    @abstractmethod
    def url_base_site(self) -> str:
        """URL base do site (sem https://)"""
        pass
    
    @abstractmethod
    def construir_url_busca(self, medicamento: str) -> str:
        """
        Constr√≥i URL de busca espec√≠fica para o medicamento
        
        Args:
            medicamento: Nome do medicamento
            
        Returns:
            str: URL completa de busca
        """
        pass
    
    @abstractmethod
    def extrair_produtos_pagina(self, soup, medicamento: str, metodo_usado: str) -> List[InfoProduto]:
        """
        Extrai produtos da p√°gina usando BeautifulSoup
        Deve ser implementado por cada site espec√≠fico
        
        Args:
            soup: BeautifulSoup da p√°gina
            medicamento: Nome do medicamento buscado
            metodo_usado: M√©todo usado para obter a p√°gina (requests/selenium)
            
        Returns:
            List[InfoProduto]: Lista de produtos encontrados
        """
        pass
    
    def buscar_medicamento(self, medicamento: str) -> List[InfoProduto]:
        """
        Busca um medicamento espec√≠fico no site
        
        Args:
            medicamento: Nome do medicamento
            
        Returns:
            List[InfoProduto]: Produtos encontrados
        """
        logger.info(f"üîç {self.nome_site}: Buscando {medicamento}")
        produtos = []
        
        try:
            # Construir URL de busca
            url_busca = self.construir_url_busca(medicamento)
            
            # Obter conte√∫do da p√°gina
            soup, metodo = self.gerenciador_conexao.obter_soup_pagina(url_busca)
            
            if not soup:
                logger.warning(f"‚ùå {self.nome_site}: Falha ao acessar p√°gina para {medicamento}")
                self.estatisticas['medicamentos_sem_resultado'] += 1
                return produtos
            
            # Extrair produtos da p√°gina
            produtos = self.extrair_produtos_pagina(soup, medicamento, metodo)
            
            # Limitar produtos se modo teste
            if self.modo_teste and produtos:
                produtos = produtos[:1]
                logger.info(f"‚ö° Modo teste: limitando a 1 produto para {medicamento}")
            
            # Atualizar estat√≠sticas
            self.estatisticas['medicamentos_processados'] += 1
            self.estatisticas['produtos_encontrados'] += len(produtos)
            
            if not produtos:
                self.estatisticas['medicamentos_sem_resultado'] += 1
                logger.info(f"‚ö™ {self.nome_site}: Nenhum produto encontrado para {medicamento}")
            else:
                logger.info(f"‚úÖ {self.nome_site}: {len(produtos)} produto(s) encontrado(s) para {medicamento}")
            
            # Pausa entre buscas para n√£o sobrecarregar o servidor
            self._pausa_entre_buscas()
            
        except Exception as e:
            logger.error(f"‚ùå {self.nome_site}: Erro ao buscar {medicamento}: {e}")
            self.estatisticas['medicamentos_sem_resultado'] += 1
        
        return produtos
    
    def executar_scraping_completo(self) -> List[Dict]:
        """
        Executa scraping de todos os medicamentos cadastrados
        
        Returns:
            List[Dict]: Dados de todos os produtos encontrados
        """
        logger.info(f"üöÄ Iniciando scraping completo - {self.nome_site}")
        self.estatisticas['tempo_inicio'] = datetime.now()
        
        # Preparar site (cookies, etc.)
        self.gerenciador_conexao.preparar_site(self.url_base_site)
        
        produtos_coletados = []
        medicamentos = self.gerenciador_dados.obter_lista_medicamentos()
        
        logger.info(f"üìã {len(medicamentos)} medicamentos para processar")
        
        # Processar cada medicamento
        for indice, medicamento in enumerate(medicamentos, 1):
            try:
                logger.info(f"üì¶ [{indice}/{len(medicamentos)}] Processando {medicamento}")
                
                # Buscar produtos do medicamento
                produtos = self.buscar_medicamento(medicamento)
                
                # Converter para dicion√°rios e adicionar √† lista
                produtos_dict = [asdict(produto) for produto in produtos]
                produtos_coletados.extend(produtos_dict)
                
            except KeyboardInterrupt:
                logger.info("‚ö†Ô∏è Scraping interrompido pelo usu√°rio")
                break
            except Exception as e:
                logger.error(f"‚ùå Erro cr√≠tico ao processar {medicamento}: {e}")
                continue
        
        self.estatisticas['tempo_fim'] = datetime.now()
        self._log_estatisticas_finais(len(produtos_coletados))
        
        return produtos_coletados
    
    def _pausa_entre_buscas(self):
        """Pausa aleat√≥ria entre buscas para simular comportamento humano"""
        if self.modo_teste:
            # Pausa menor em modo teste
            delay = random.uniform(0.5, 1.5)
        else:
            # Pausa normal em modo produ√ß√£o
            delay = random.uniform(1.0, 3.0)
        
        time.sleep(delay)
    
    def _log_estatisticas_finais(self, total_produtos: int):
        """
        Registra estat√≠sticas finais do scraping
        
        Args:
            total_produtos: Total de produtos coletados
        """
        tempo_total = None
        if self.estatisticas['tempo_inicio'] and self.estatisticas['tempo_fim']:
            tempo_total = self.estatisticas['tempo_fim'] - self.estatisticas['tempo_inicio']
            tempo_total = tempo_total.total_seconds()
        
        logger.info(f"üìä {self.nome_site} - Estat√≠sticas finais:")
        logger.info(f"   ‚Ä¢ Medicamentos processados: {self.estatisticas['medicamentos_processados']}")
        logger.info(f"   ‚Ä¢ Produtos encontrados: {total_produtos}")
        logger.info(f"   ‚Ä¢ Medicamentos sem resultado: {self.estatisticas['medicamentos_sem_resultado']}")
        
        if tempo_total:
            logger.info(f"   ‚Ä¢ Tempo total: {tempo_total:.1f}s")
            if self.estatisticas['medicamentos_processados'] > 0:
                tempo_medio = tempo_total / self.estatisticas['medicamentos_processados']
                logger.info(f"   ‚Ä¢ Tempo m√©dio por medicamento: {tempo_medio:.1f}s")
    
    def obter_estatisticas(self) -> dict:
        """
        Retorna estat√≠sticas detalhadas do scraper
        
        Returns:
            dict: Estat√≠sticas completas
        """
        stats = self.estatisticas.copy()
        stats['nome_site'] = self.nome_site
        stats['modo_teste'] = self.modo_teste
        
        return stats